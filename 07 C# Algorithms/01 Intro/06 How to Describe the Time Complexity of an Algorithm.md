# â±ï¸ How to Describe the Time Complexity of an Algorithm

## ðŸ“˜ Introduction

Some algorithms are more efficient than others. To measure and compare this efficiency, we use **Big-O notation**. Big-O describes an algorithmâ€™s performance in terms of **time** (execution speed) and sometimes **space** (memory usage), regardless of input size.

---

## ðŸ”Ž What is Big-O Notation?

Big-O notation:

* Provides a **high-level measure** of algorithm efficiency.
* Expresses how runtime (or memory usage) grows with input size $N$.
* Lets us compare algorithms **independent of input size**.

---

## ðŸ” Example: Search Algorithms

1. **Constant Time (O(1))**

   * If the item is always the **first or last** element in a list.
   * Only need to check one (or two) positions, regardless of input size.

   ðŸ‘‰ **Efficiency:** Runtime does not change with input size.

2. **Linear Time (O(N))**

   * If the item could be **anywhere in the list** and we donâ€™t know where.
   * Might need to check **every element**.
   * **Best Case:** First item matches (O(1)).
   * **Worst Case:** Item doesnâ€™t exist â†’ must check all N elements (O(N)).

   ðŸ‘‰ **Efficiency:** Runtime increases directly with input size.

---

## âš–ï¸ Best Case vs Worst Case

* **Best Case:** Minimum number of steps (ideal scenario).
* **Worst Case:** Maximum number of steps (pessimistic scenario).
* **Average Case:** Typical performance over many runs.

ðŸ“Œ In practice, we usually focus on the **worst case** when evaluating algorithms.

---

## ðŸ“Š Common Time Complexities

* **O(1)** â†’ Constant time â†’ Fastest.
* **O(log N)** â†’ Logarithmic â†’ Example: Binary search.
* **O(N)** â†’ Linear â†’ Example: Linear search.
* **O(N log N)** â†’ Linearithmic â†’ Example: Merge Sort, Quick Sort (average).
* **O(NÂ²)** â†’ Quadratic â†’ Example: Bubble Sort, Insertion Sort (worst case).
* **O(2^N)** â†’ Exponential â†’ Example: Some recursive algorithms.
* **O(N!)** â†’ Factorial â†’ Example: Brute-force traveling salesman.

ðŸ‘‰ The higher the growth rate, the **less efficient** the algorithm becomes as input size increases.

---

## ðŸ—‚ï¸ Space Complexity

Big-O also describes **space usage**:

* **O(1):** Constant memory.
* **O(N):** Memory grows proportionally with input size.

Example:

* A simple counter uses O(1) space.
* Storing all elements of an input list requires O(N) space.

---

## âœ… Summary

* **Big-O notation** measures algorithm efficiency in terms of time and space.
* Focus is often on the **worst case** scenario.
* **Assumptions about data** can help reduce complexity (e.g., assuming sorted data).
* Common complexities: **O(1) â†’ O(log N) â†’ O(N) â†’ O(N log N) â†’ O(NÂ²) â†’ O(2^N)**.
* Big-O allows us to compare algorithms **independently of input size**.

> ðŸ”‘ **Key Idea:** Big-O = A mathematical way to compare algorithm efficiency as input size grows.
